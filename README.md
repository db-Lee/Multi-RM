# Rethinking Reward Models for Multi-Domain Test-Time Scaling
[![arXiv](https://img.shields.io/badge/arXiv-Read%20paper-b31b1b?style=flat&logo=arXiv&logoColor=white)](https://arxiv.org/abs/ARXIV_ID)

This repository contains the codebase for our paper, "**Rethinking Reward Models for Multi-Domain Test-Time Scaling**."

---

## Abstract



## Synthetic Verfication Rationale Generation for gORM/gPRM (optional)

```python
# TASK_TYPE can be one of:
# gORM / gPRM
TASK_TYPE=[choose_one_above]

# generate data
python -m data_generation.generate_data \
  --output_dir [OUTPUT_DIR] \
  --task_type ${TASK_TYPE}

# preprocess data
python -m data_generation.preprocess_data \
  --output_dir [OUTPUT_DIR] \
  --task_type ${TASK_TYPE}

# shorten critique (optional)
python -m data_generation.shorten_critique \
  --output_dir [OUTPUT_DIR] \
  --task_type ${TASK_TYPE}
```

---

## Training

```python
# Training dORM / dPRM
# Use the appropriate config file:
# ./configs/dORM-14B.yaml
# ./configs/dPRM-14B.yaml
# ./configs/dORM-8B.yaml
# ./configs/dPRM-8B.yaml

accelerate launch -m discriminative.train \
  --config ./configs/dORM-14B.yaml \
  --output_dir ./[TRAINING_RESULTS]/dORM-14B \
  --per_device_batch_size 4 \# tuned for H200; adjust for your GPU
  --category all

# Training gORM / gPRM
# Use the appropriate config file:
# ./configs/gORM-14B.yaml
# ./configs/gPRM-14B.yaml
# ./configs/gORM-8B.yaml
# ./configs/gPRM-8B.yaml

accelerate launch -m generative.train \
  --config ./configs/dORM-14B.yaml \
  --output_dir ./[TRAINING_RESULTS]/dORM-14B \
  --per_device_batch_size 4 \# tuned for H200; adjust for your GPU
  --category all
```

---

## Inference (reward)

```python
# TEST can be one of:
# test (CoTs generated by Llama3.1-8B-Instruct)
# test_smollm (CoTs generated by Smollm3)
# test_qwen (CoTs generated by Qwen2.5-7B-Instruct)
# test_gemma (CoTs generated by gemma2-9B-it)
# test_llama (CoTs generated by Llama3.1-80B-Instruct)

# Inference for dORM / dPRM
# Use the appropriate model checkpoint:
# dongboklee/dORM-14B
# dongboklee/dPRM-14B

python -m discriminative.get_reward \
  --data_path dongboklee/[TEST] \
  --model_id dongboklee/dORM-14B \# or use your own trained models
  --output_dir ./[REWARD_RESULTS]/dORM-14B-[TEST] \
  --per_device_batch_size 8 \# tuned for H200; adjust for your GPU
  --category all

# Inference for gORM / gPRM
# Use the appropriate model checkpoint:
# dongboklee/gORM-14B-merged, TASK_TYPE=gORM
# dongboklee/gPRM-14B-merged, TASK_TYPE=gPRM

python -m generative.get_reward \
  --data_path dongboklee/[TEST] \
  --model_id dongboklee/gORM-14B-merged
  --output_dir ./[REWARD_RESULTS]/gORM-14B-[TEST] \
  --task_type gORM \
  --category all

# Inference for gORM / gPRM (for your own trained models)
# Use the appropriate model checkpoint:
# [LOCAL_DIR]/gORM-14B, TASK_TYPE=gORM
# [LOCAL_DIR]/gPRM-14B, TASK_TYPE=gPRM

# Merge LoRA for vLLM inference
python -m generative.merge_lora \
  --input_dir [LOCAL_DIR]/gORM-14B # saved to [LOCAL_DIR]/gORM-14B/tmp

python -m generative.get_reward \
  --data_path dongboklee/[TEST] \
  --model_id [LOCAL_DIR]/gORM-14B/tmp
  --output_dir ./[REWARD_RESULTS]/gORM-14B-[TEST] \
  --task_type gORM \
  --category all
```

---

## Evaluation
```python
# TEST can be one of:
# test (CoTs generated by Llama3.1-8B-Instruct)
# test_smollm (CoTs generated by Smollm3)
# test_qwen (CoTs generated by Qwen2.5-7B-Instruct)
# test_gemma (CoTs generated by gemma2-9B-it)
# test_llama (CoTs generated by Llama3.1-80B-Instruct)
TEST=[choose_one_above]

# (Optional) Use a LOCAL reward directory with the structure:
# [LOCAL_DIR]/[MODEL_NAME]/[TEST]/[CATEGORY]_reward.json

python -m evaluation.evaluate \
  --data_path dongboklee/${TEST} \
  --output_dir [OUTPUT_DIR] \
  --reward_dirs \
    dongboklee/dORM-14B-${TEST} \
    dongboklee/dPRM-14B-${TEST} \
    dongboklee/gORM-14B-${TEST} \
    dongboklee/gPRM-14B-${TEST} \
  # Or use your own reward dirs instead of HF hubs:
  # --reward_dirs \
  #   [LOCAL_DIR]/dORM-14B-${TEST} \
  #   [LOCAL_DIR]/dPRM-14B-${TEST} \
  #   [LOCAL_DIR]/gORM-14B-${TEST} \
  #   [LOCAL_DIR]/gPRM-14B-${TEST} \
  --model_names dORM-14B dPRM-14B gORM-14B gPRM-14B \
  --strategies last min mean mean \
  --num_runs 100

# CSV_FILE can be one of:
# [OUTPUT_DIR_FROM_ABOVE]/best_of_n.csv
# [OUTPUT_DIR_FROM_ABOVE]/weighted_vote.csv
CSV_FILE=[choose_one_above]

python -m evaluation.plot \
  --input_file ${CSV_FILE} \
  --output_file [OUTPUT_FILE_PREFIX] # example -> example_legend.png / example_legend.pdf / example.png / example.pdf
```

---

## Assets

Please find the assets of this repo below, including training and test datasets, model checkpoints, and rewards obtained by the four reward model variants.

---

### Training Datasets

- [train](https://huggingface.co/datasets/dongboklee/train): multi-domain training dataset for dORM/dPRM (mostly adapted from [VersaPRM](https://github.com/UW-Madison-Lee-Lab/VersaPRM)).
- [train_gORM](https://huggingface.co/datasets/dongboklee/train_gORM): multi-domain training dataset for gORM generated by [QwQ-32B](https://huggingface.co/Qwen/QwQ-32B).
- [train_gPRM](https://huggingface.co/datasets/dongboklee/train_gPRM): multi-domain training dataset for gPRM generated by [QwQ-32B](https://huggingface.co/Qwen/QwQ-32B).

---

### Test Datasets

- [test](https://huggingface.co/datasets/dongboklee/test): multi-domain test dataset with CoTs (N=128) generated by [Llama3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) (mostly adapted from [VersaPRM](https://github.com/UW-Madison-Lee-Lab/VersaPRM)).
- [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm): multi-domain test dataset with CoTs (N=16) generated by [SmolLM3-3B](https://huggingface.co/HuggingFaceTB/SmolLM3-3B).
- [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen): multi-domain test dataset with CoTs (N=16) generated by [Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct).
- [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma): multi-domain test dataset with CoTs (N=16) generated by [gemma-2-9b-it](https://huggingface.co/google/gemma-2-9b-it).
- [test_llama](https://huggingface.co/datasets/dongboklee/test_llama): multi-domain test dataset with CoTs (N=16) generated by [Llama-3.1-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct).

---

### Model Checkpoints

- [dORM-14B](https://huggingface.co/dongboklee/dORM-14B): dORM with [14B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) trained on [train](https://huggingface.co/datasets/dongboklee/train).
- [dPRM-14B](https://huggingface.co/dongboklee/dPRM-14B): dPRM with [14B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) trained on [train](https://huggingface.co/datasets/dongboklee/train).
- [gORM-14B](https://huggingface.co/dongboklee/gORM-14B): gORM with [14B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) trained on [train_gORM](https://huggingface.co/datasets/dongboklee/train_gORM).
- [gORM-14B-merged](https://huggingface.co/dongboklee/gORM-14B-merged): LoRA-merged version of [gORM-14B](https://huggingface.co/dongboklee/gORM-14B) for vLLM inference.
- [gPRM-14B](https://huggingface.co/dongboklee/gPRM-14B): gPRM with [14B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) trained on [train_gPRM](https://huggingface.co/datasets/dongboklee/train_gPRM).  
- [gPRM-14B-merged](https://huggingface.co/dongboklee/gPRM-14B-merged): LoRA-merged version of [gPRM-14B](https://huggingface.co/dongboklee/gPRM-14B) for vLLM inference.

- [dORM-8B](https://huggingface.co/dongboklee/dORM-8B): dORM with [8B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) trained on [train](https://huggingface.co/datasets/dongboklee/train).
- [dPRM-8B](https://huggingface.co/dongboklee/dPRM-8B): dPRM with [8B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) trained on [train](https://huggingface.co/datasets/train).
- [gORM-8B](https://huggingface.co/dongboklee/gORM-8B): gORM with [8B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) trained on [train_gORM](https://huggingface.co/datasets/dongboklee/train_gORM).
- [gORM-8B-merged](https://huggingface.co/dongboklee/gORM-8B-merged): LoRA-merged version of [gORM-8B](https://huggingface.co/dongboklee/gORM-8B) for vLLM inference.
- [gPRM-8B](https://huggingface.co/dongboklee/gPRM-8B): gPRM with [8B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) trained on [train_gPRM](https://huggingface.co/datasets/dongboklee/train_gPRM).  
- [gPRM-8B-merged](https://huggingface.co/dongboklee/gPRM-8B-merged): LoRA-merged version of [gPRM-8B](https://huggingface.co/dongboklee/gPRM-8B) for vLLM inference.
---

### Reward obtained by dORM-14B/-8B

- [dORM-14B-test](https://huggingface.co/datasets/dongboklee/dORM-14B-test): reward obtained by [dORM-14B](https://huggingface.co/dongboklee/dORM-14B) on [test](https://huggingface.co/datasets/dongboklee/test).
- [dORM-8B-test](https://huggingface.co/datasets/dongboklee/dORM-8B-test): reward obtained by [dORM-8B](https://huggingface.co/dongboklee/dORM-8B) on [test](https://huggingface.co/datasets/dongboklee/test).
- [dORM-14B-test_smollm](https://huggingface.co/datasets/dongboklee/dORM-14B-test_smollm): reward obtained by [dORM-14B](https://huggingface.co/dongboklee/dORM-14B) on [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm).
- [dORM-14B-test_qwen](https://huggingface.co/datasets/dongboklee/dORM-14B-test_qwen): reward obtained by [dORM-14B](https://huggingface.co/dongboklee/dORM-14B) on [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen).
- [dORM-14B-test_gemma](https://huggingface.co/datasets/dongboklee/dORM-14B-test_gemma): reward obtained by [dORM-14B](https://huggingface.co/dongboklee/dORM-14B) on [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma).
- [dORM-14B-test_llama](https://huggingface.co/datasets/dongboklee/dORM-14B-test_llama): reward obtained by [dORM-14B](https://huggingface.co/dongboklee/dORM-14B) on [test_llama](https://huggingface.co/datasets/dongboklee/test_llama).

---

### Reward obtained by dPRM-14B/-8B

- [dPRM-14B-test](https://huggingface.co/datasets/dongboklee/dPRM-14B-test): reward obtained by [dPRM-14B](https://huggingface.co/dongboklee/dPRM-14B) on [test](https://huggingface.co/datasets/dongboklee/test).
- [dPRM-8B-test](https://huggingface.co/datasets/dongboklee/dPRM-8B-test): reward obtained by [dPRM-8B](https://huggingface.co/dPRM-8B) on [test](https://huggingface.co/datasets/dongboklee/test).
- [dPRM-14B-test_smollm](https://huggingface.co/datasets/dongboklee/dPRM-14B-test_smollm): reward obtained by [dPRM-14B](https://huggingface.co/dongboklee/dPRM-14B) on [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm).
- [dPRM-14B-test_qwen](https://huggingface.co/datasets/dongboklee/dPRM-14B-test_qwen): reward obtained by [dPRM-14B](https://huggingface.co/dongboklee/dPRM-14B) on [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen).
- [dPRM-14B-test_gemma](https://huggingface.co/datasets/dongboklee/dPRM-14B-test_gemma): reward obtained by [dPRM-14B](https://huggingface.co/dongboklee/dPRM-14B) on [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma).
- [dPRM-14B-test_llama](https://huggingface.co/datasets/dongboklee/dPRM-14B-test_llama): reward obtained by [dPRM-14B](https://huggingface.co/dongboklee/dPRM-14B) on [test_llama](https://huggingface.co/datasets/dongboklee/test_llama).

---

### Reward obtained by gORM-14B/-8B

- [gORM-14B-test](https://huggingface.co/datasets/dongboklee/gORM-14B-test): reward obtained by [gORM-14B-merged](https://huggingface.co/dongboklee/gORM-14B-merged) on [test](https://huggingface.co/datasets/dongboklee/test).
- [gORM-8B-test](https://huggingface.co/datasets/dongboklee/gORM-8B-test): reward obtained by [gORM-8B-merged](https://huggingface.co/dongboklee/gORM-8B-merged) on [test](https://huggingface.co/datasets/dongboklee/test).
- [gORM-14B-test_smollm](https://huggingface.co/datasets/dongboklee/gORM-14B-test_smollm): reward obtained by [gORM-14B-merged](https://huggingface.co/dongboklee/gORM-14B-merged) on [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm).
- [gORM-14B-test_qwen](https://huggingface.co/datasets/dongboklee/gORM-14B-test_qwen): reward obtained by [gORM-14B-merged](https://huggingface.co/dongboklee/gORM-14B-merged) on [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen).
- [gORM-14B-test_gemma](https://huggingface.co/datasets/dongboklee/gORM-14B-test_gemma): reward obtained by [gORM-14B-merged](https://huggingface.co/dongboklee/gORM-14B-merged) on [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma).
- [gORM-14B-test_llama](https://huggingface.co/datasets/dongboklee/gORM-14B-test_llama): reward obtained by [gORM-14B-merged](https://huggingface.co/dongboklee/gORM-14B-merged) on [test_llama](https://huggingface.co/datasets/dongboklee/test_llama).

---

### Reward obtained by gPRM-14B/-8B

- [gPRM-14B-test](https://huggingface.co/datasets/dongboklee/gPRM-14B-test): reward obtained by [gPRM-14B-merged](https://huggingface.co/dongboklee/gPRM-14B-merged) on [test](https://huggingface.co/datasets/dongboklee/test).
- [gPRM-8B-test](https://huggingface.co/datasets/dongboklee/gPRM-8B-test): reward obtained by [gPRM-8B-merged](https://huggingface.co/dongboklee/gPRM-8B-merged) on [test](https://huggingface.co/datasets/dongboklee/test).
- [gPRM-14B-test_smollm](https://huggingface.co/datasets/dongboklee/gPRM-14B-test_smollm): reward obtained by [gPRM-14B-merged](https://huggingface.co/dongboklee/gPRM-14B-merged) on [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm).
- [gPRM-14B-test_qwen](https://huggingface.co/datasets/dongboklee/gPRM-14B-test_qwen): reward obtained by [gPRM-14B-merged](https://huggingface.co/dongboklee/gPRM-14B-merged) on [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen).
- [gPRM-14B-test_gemma](https://huggingface.co/datasets/dongboklee/gPRM-14B-test_gemma): reward obtained by [gPRM-14B-merged](https://huggingface.co/dongboklee/gPRM-14B-merged) on [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma).
- [gPRM-14B-test_llama](https://huggingface.co/datasets/dongboklee/gPRM-14B-test_llama): reward obtained by [gPRM-14B-merged](https://huggingface.co/dongboklee/gPRM-14B-merged) on [test_llama](https://huggingface.co/datasets/dongboklee/test_llama).

---

### Citation
```
@article{multi-rm,
  title={Rethinking Reward Models for Multi-Domain Test-Time Scaling},
  author={Khalifa, Muhammad and Agarwal, Rishabh and Logeswaran, Lajanugen and Kim, Jaekyeom and Peng, Hao and Lee, Moontae and Lee, Honglak and Wang, Lu},
  journal={arXiv preprint arXiv:2504.16828},
  year={2025}
}
```
