# Rethinking Reward Models for Multi-Domain Test-Time Scaling

## Synthetic Verfication Rationale Generation for gORM/gPRM

```python
# TASK_TYPE can be one of:
# gORM / gPRM
TASK_TYPE=[choose_one_above]

# generate data
python -m data_generation.generate_data \
  --output_dir [OUTPUT_DIR] \
  --task_type ${TASK_TYPE}

# preprocess data
python -m data_generation.preprocess_data \
  --output_dir [OUTPUT_DIR] \
  --task_type ${TASK_TYPE}

# shorten critique (optional)
python -m data_generation.shorten_critique \
  --output_dir [OUTPUT_DIR] \
  --task_type ${TASK_TYPE}
```

---

## Training

```python
# Training dORM / dPRM
# Use the appropriate config file:
# ./configs/dORM-14B.yaml
# ./configs/dPRM-14B.yaml

accelerate launch -m discriminative.train \
  --config ./configs/dORM-14B.yaml \
  --output_dir ./[TRAINING_RESULTS]/dORM-14B \
  --per_device_batch_size 4 \# tuned for H200; adjust for your GPU
  --category all

# Training gORM / gPRM
# Use the appropriate config file:
# ./configs/gORM-14B.yaml
# ./configs/gPRM-14B.yaml

accelerate launch -m generative.train \
  --config ./configs/dORM-14B.yaml \
  --output_dir ./[TRAINING_RESULTS]/dORM-14B \
  --per_device_batch_size 4 \# tuned for H200; adjust for your GPU
  --category all
```

---

## Inference (reward)

```python
# TEST can be one of:
# test / test_smollm / test_qwen / test_gemma / test_llama

# Inference for dORM / dPRM
# Use the appropriate model checkpoint:
# dongboklee/dORM-14B
# dongboklee/dPRM-14B

python -m discriminative.get_reward \
  --data_path dongboklee/[TEST] \
  --model_id dongboklee/dORM-14B \# or use your own trained models
  --output_dir ./[REWARD_RESULTS]/dORM-14B-[TEST] \
  --per_device_batch_size 8 \# tuned for H200; adjust for your GPU
  --category all

# Inference for gORM / gPRM
# Use the appropriate model checkpoint:
# dongboklee/gORM-14B
# dongboklee/gPRM-14B

python -m generative.get_reward \
  --data_path dongboklee/[TEST] \
  --model_id dongboklee/gORM-14B \# or use your own trained models
  --output_dir ./[REWARD_RESULTS]/gORM-14B-[TEST] \
  --category all
```

---

## Evaluation
- CSV file extraction
```python
# TEST can be one of:
# test / test_smollm / test_qwen / test_gemma / test_llama
TEST=[choose_one_above]

# (Optional) Use a LOCAL reward directory with the structure:
# [LOCAL_DIR]/[MODEL_NAME]/[TEST]/[CATEGORY]_reward.json

python -m evaluation.evaluate \
  --data_path dongboklee/${TEST} \
  --output_dir [OUTPUT_DIR] \
  --reward_dirs \
    dongboklee/dORM-14B-${TEST} \
    dongboklee/dPRM-14B-${TEST} \
    dongboklee/gORM-14B-${TEST} \
    dongboklee/gPRM-14B-${TEST} \
  # Or use local reward dirs instead of HF hubs:
  # --reward_dirs \
  #   [LOCAL_DIR]/dORM-14B-${TEST} \
  #   [LOCAL_DIR]/dPRM-14B-${TEST} \
  #   [LOCAL_DIR]/gORM-14B-${TEST} \
  #   [LOCAL_DIR]/gPRM-14B-${TEST} \
  --model_names dORM-14B dPRM-14B gORM-14B gPRM-14B \
  --strategies last min mean mean \
  --num_runs 100
```
---
- Plot
```python
# CSV_FILE can be one of:
# [OUTPUT_DIR_FROM_ABOVE]/best_of_n.csv
# [OUTPUT_DIR_FROM_ABOVE]/weighted_vote.csv
CSV_FILE=[choose_one_above]

python -m evaluation.plot \
  --input_file ${CSV_FILE} \
  --output_file [OUTPUT_FILE_PREFIX]
```
---

## Assets

Please find the assets of this repo below, including training and test datasets, model checkpoints, and rewards obtained by the four variants.

---

### Training Datasets

- [train](https://huggingface.co/datasets/dongboklee/train): the multi-domain training dataset for dORM/dPRM (mostly adapted from [VersaPRM](https://github.com/UW-Madison-Lee-Lab/VersaPRM)).
- [train_gORM](https://huggingface.co/datasets/dongboklee/train_gORM): the multi-domain training dataset for gORM generated by [QwQ-32B](https://huggingface.co/Qwen/QwQ-32B).
- [train_gPRM](https://huggingface.co/datasets/dongboklee/train_gPRM): the multi-domain training dataset for gPRM generated by [QwQ-32B](https://huggingface.co/Qwen/QwQ-32B).

---

### Test Datasets

- [test](https://huggingface.co/datasets/dongboklee/test): the multi-domain test dataset (N=128) generated by [Llama3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) (mostly adapted from [VersaPRM](https://github.com/UW-Madison-Lee-Lab/VersaPRM)).
- [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm): the multi-domain test dataset (N=16) generated by [SmolLM3-3B](hf.co/HuggingFaceTB/SmolLM3-3B).
- [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen): the multi-domain test dataset (N=16) generated by [Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct).
- [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma): the multi-domain test dataset (N=16) generated by [gemma-2-9b-it](https://huggingface.co/google/gemma-2-9b-it).
- [test_llama](https://huggingface.co/datasets/dongboklee/test_llama): the multi-domain test dataset (N=16) generated by [Llama-3.1-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct).

---

### Model Checkpoints

- [dORM-14B](https://huggingface.co/datasets/dongboklee/dORM-14B): dORM with [14B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) trained on the multi-domain training dataset ([train](https://huggingface.co/datasets/dongboklee/train)).
- [dPRM-14B](https://huggingface.co/datasets/dongboklee/dPRM-14B): dPRM with [14B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) trained on the multi-domain training dataset ([train](https://huggingface.co/datasets/dongboklee/train)).
- [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B): gORM with [14B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) trained on the multi-domain training dataset ([train_orm](https://huggingface.co/datasets/dongboklee/train_orm)).
- [gPRM-14B](https://huggingface.co/datasets/dongboklee/gPRM-14B): gPRM with [14B backbone](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) trained on the multi-domain training dataset ([train_prm](https://huggingface.co/datasets/dongboklee/train_prm)).

---

### Reward obtained by dORM-14B

- [dORM-14B-test](https://huggingface.co/datasets/dongboklee/dORM-14B-test): reward obtained by [dORM-14B](https://huggingface.co/datasets/dongboklee/dORM-14B) on [test](https://huggingface.co/datasets/dongboklee/test).
- [dORM-14B-test_smollm](https://huggingface.co/datasets/dongboklee/dORM-14B-test_smollm): reward obtained by [dORM-14B](https://huggingface.co/datasets/dongboklee/dORM-14B) on [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm).
- [dORM-14B-test_qwen](https://huggingface.co/datasets/dongboklee/dORM-14B-test_qwen): reward obtained by [dORM-14B](https://huggingface.co/datasets/dongboklee/dORM-14B) on [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen).
- [dORM-14B-test_gemma](https://huggingface.co/datasets/dongboklee/dORM-14B-test_gemma): reward obtained by [dORM-14B](https://huggingface.co/datasets/dongboklee/dORM-14B) on [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma).
- [dORM-14B-test_llama](https://huggingface.co/datasets/dongboklee/dORM-14B-test_llama): reward obtained by [dORM-14B](https://huggingface.co/datasets/dongboklee/dORM-14B) on [test_llama](https://huggingface.co/datasets/dongboklee/test_llama).

---

### Reward obtained by dPRM-14B

- [dPRM-14B-test](https://huggingface.co/datasets/dongboklee/dPRM-14B-test): reward obtained by [dPRM-14B](https://huggingface.co/datasets/dongboklee/dPRM-14B) on [test](https://huggingface.co/datasets/dongboklee/test).
- [dPRM-14B-test_smollm](https://huggingface.co/datasets/dongboklee/dPRM-14B-test_smollm): reward obtained by [dPRM-14B](https://huggingface.co/datasets/dongboklee/dPRM-14B) on [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm).
- [dPRM-14B-test_qwen](https://huggingface.co/datasets/dongboklee/dPRM-14B-test_qwen): reward obtained by [dPRM-14B](https://huggingface.co/datasets/dongboklee/dPRM-14B) on [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen).
- [dPRM-14B-test_gemma](https://huggingface.co/datasets/dongboklee/dPRM-14B-test_gemma): reward obtained by [dPRM-14B](https://huggingface.co/datasets/dongboklee/dPRM-14B) on [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma).
- [dPRM-14B-test_llama](https://huggingface.co/datasets/dongboklee/dPRM-14B-test_llama): reward obtained by [dPRM-14B](https://huggingface.co/datasets/dongboklee/dPRM-14B) on [test_llama](https://huggingface.co/datasets/dongboklee/test_llama).

---

### Reward obtained by gORM-14B

- [gORM-14B-test](https://huggingface.co/datasets/dongboklee/gORM-14B-test): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test](https://huggingface.co/datasets/dongboklee/test).
- [gORM-14B-test_smollm](https://huggingface.co/datasets/dongboklee/gORM-14B-test_smollm): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm).
- [gORM-14B-test_qwen](https://huggingface.co/datasets/dongboklee/gORM-14B-test_qwen): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen).
- [gORM-14B-test_gemma](https://huggingface.co/datasets/dongboklee/gORM-14B-test_gemma): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma).
- [gORM-14B-test_llama](https://huggingface.co/datasets/dongboklee/gORM-14B-test_llama): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test_llama](https://huggingface.co/datasets/dongboklee/test_llama).

---

### Reward obtained by gORM-14B

- [gORM-14B-test](https://huggingface.co/datasets/dongboklee/gORM-14B-test): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test](https://huggingface.co/datasets/dongboklee/test).
- [gORM-14B-test_smollm](https://huggingface.co/datasets/dongboklee/gORM-14B-test_smollm): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test_smollm](https://huggingface.co/datasets/dongboklee/test_smollm).
- [gORM-14B-test_qwen](https://huggingface.co/datasets/dongboklee/gORM-14B-test_qwen): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test_qwen](https://huggingface.co/datasets/dongboklee/test_qwen).
- [gORM-14B-test_gemma](https://huggingface.co/datasets/dongboklee/gORM-14B-test_gemma): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test_gemma](https://huggingface.co/datasets/dongboklee/test_gemma).
- [gORM-14B-test_llama](https://huggingface.co/datasets/dongboklee/gORM-14B-test_llama): reward obtained by [gORM-14B](https://huggingface.co/datasets/dongboklee/gORM-14B) on [test_llama](https://huggingface.co/datasets/dongboklee/test_llama).

---
